{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/25 17:48:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/25 17:48:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/25 17:48:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://robsons-imac.lan:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Advanced</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fee25c599d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Advanced\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('/Users/rob_the_programmer/Documents/programming/2022/hands_on_data_science/spark-sql-dataframes-workspace/files/utlization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|    cpu_utilization|     event_datetime|        free_memory|         server_id|     session_count|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|             500000|             500000|             500000|            500000|            500000|\n",
      "|   mean| 0.6205177400000106|               null| 0.3791280999999971|             124.5|          69.59616|\n",
      "| stddev|0.15875173872912937|               null|0.15830931278376237|14.430884120552962|14.850676696352718|\n",
      "|    min|               0.22|03/05/2019 08:06:14|                0.0|               100|                32|\n",
      "|    max|                1.0|04/09/2019 01:22:46|               0.78|               149|               105|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|    cpu_utilization|        free_memory|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|             500000|             500000|\n",
      "|   mean| 0.6205177400000106| 0.3791280999999971|\n",
      "| stddev|0.15875173872912937|0.15830931278376237|\n",
      "|    min|               0.22|                0.0|\n",
      "|    max|                1.0|               0.78|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe('cpu_utilization', 'free_memory').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.47047715730807543"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.corr('cpu_utilization', 'free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+\n",
      "| server_id_freqItems|session_count_freqItems|\n",
      "+--------------------+-----------------------+\n",
      "|[146, 137, 101, 1...|   [92, 101, 83, 104...|\n",
      "+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.stat.freqItems(['server_id', 'session_count']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24764"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsample = df.sample(fraction=0.05, withReplacement=False)\n",
    "dfsample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------------------+\n",
      "|min_cpu_utilization|max_cpu_utilization|stddev_cpu_utilization|\n",
      "+-------------------+-------------------+----------------------+\n",
      "|               0.22|                1.0|   0.15875173872912937|\n",
      "+-------------------+-------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select \n",
    "        min(cpu_utilization) as min_cpu_utilization,\n",
    "        max(cpu_utilization) as max_cpu_utilization,\n",
    "        stddev(cpu_utilization) as stddev_cpu_utilization\n",
    "    from utilization\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+----------------------+\n",
      "|server_id|min_cpu_utilization|max_cpu_utilization|stddev_cpu_utilization|\n",
      "+---------+-------------------+-------------------+----------------------+\n",
      "|      112|               0.52|               0.92|   0.11528867845082576|\n",
      "|      113|               0.58|               0.98|   0.11544345150353687|\n",
      "|      110|               0.35|               0.75|   0.11533251724450215|\n",
      "|      107|               0.45|               0.85|   0.11597417369783877|\n",
      "|      103|               0.56|               0.96|   0.11617507884178278|\n",
      "|      104|               0.51|               0.91|   0.11521679513850511|\n",
      "|      106|               0.22|               0.62|   0.11531539914568233|\n",
      "|      111|               0.36|               0.76|   0.11530221569464506|\n",
      "|      100|               0.27|               0.67|    0.1152264191787964|\n",
      "|      105|               0.29|               0.69|   0.11510721467869486|\n",
      "|      108|               0.55|               0.95|   0.11563100171171926|\n",
      "|      101|                0.6|                1.0|   0.11651726263197697|\n",
      "|      102|               0.56|               0.96|   0.11549678751286807|\n",
      "|      109|               0.36|               0.76|   0.11574898623219722|\n",
      "|      126|               0.48|               0.88|   0.11542612970702058|\n",
      "|      119|               0.22|               0.62|   0.11516031929842008|\n",
      "|      116|                0.3|                0.7|   0.11506079722349302|\n",
      "|      124|               0.24|               0.64|   0.11579377614906383|\n",
      "|      114|               0.33|               0.73|   0.11510268816097273|\n",
      "|      115|               0.44|               0.84|   0.11569664615014985|\n",
      "+---------+-------------------+-------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select \n",
    "        server_id,\n",
    "        min(cpu_utilization) as min_cpu_utilization,\n",
    "        max(cpu_utilization) as max_cpu_utilization,\n",
    "        stddev(cpu_utilization) as stddev_cpu_utilization\n",
    "    from utilization\n",
    "    group by 1\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|server_id|bucket|\n",
      "+---------+------+\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "|      100|     6|\n",
      "|      100|     6|\n",
      "|      100|     5|\n",
      "|      100|     2|\n",
      "|      100|     4|\n",
      "|      100|     4|\n",
      "|      100|     6|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select\n",
    "        server_id,\n",
    "        floor(cpu_utilization * 100/10) bucket \n",
    "    from utilization''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|count(1)|bucket|\n",
      "+--------+------+\n",
      "|    8186|     2|\n",
      "|   37029|     3|\n",
      "|   68046|     4|\n",
      "|  104910|     5|\n",
      "|  116725|     6|\n",
      "|   88242|     7|\n",
      "|   56598|     8|\n",
      "|   20207|     9|\n",
      "|      57|    10|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select\n",
    "        count(*),\n",
    "        floor(cpu_utilization * 100/10) as bucket \n",
    "    from utilization\n",
    "    group by 2\n",
    "    order by 2''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+----------------------+\n",
      "|server_id|min_cpu_utilization|max_cpu_utilization|stddev_cpu_utilization|\n",
      "+---------+-------------------+-------------------+----------------------+\n",
      "|      112|               0.52|               0.92|   0.11528867845082576|\n",
      "|      113|               0.58|               0.98|   0.11544345150353687|\n",
      "|      110|               0.35|               0.75|   0.11533251724450215|\n",
      "|      107|               0.45|               0.85|   0.11597417369783877|\n",
      "|      103|               0.56|               0.96|   0.11617507884178278|\n",
      "|      104|               0.51|               0.91|   0.11521679513850511|\n",
      "|      106|               0.22|               0.62|   0.11531539914568233|\n",
      "|      111|               0.36|               0.76|   0.11530221569464506|\n",
      "|      100|               0.27|               0.67|    0.1152264191787964|\n",
      "|      105|               0.29|               0.69|   0.11510721467869486|\n",
      "|      108|               0.55|               0.95|   0.11563100171171926|\n",
      "|      101|                0.6|                1.0|   0.11651726263197697|\n",
      "|      102|               0.56|               0.96|   0.11549678751286807|\n",
      "|      109|               0.36|               0.76|   0.11574898623219722|\n",
      "|      126|               0.48|               0.88|   0.11542612970702058|\n",
      "|      119|               0.22|               0.62|   0.11516031929842008|\n",
      "|      116|                0.3|                0.7|   0.11506079722349302|\n",
      "|      124|               0.24|               0.64|   0.11579377614906383|\n",
      "|      114|               0.33|               0.73|   0.11510268816097273|\n",
      "|      115|               0.44|               0.84|   0.11569664615014985|\n",
      "+---------+-------------------+-------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select\n",
    "        server_id,\n",
    "        min(cpu_utilization) as min_cpu_utilization,\n",
    "        max(cpu_utilization) as max_cpu_utilization,\n",
    "        stddev(cpu_utilization) as stddev_cpu_utilization\n",
    "    from utilization\n",
    "    group by 1\n",
    "    ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:31|      110|           0.68|0.5537749999999892|\n",
      "|03/05/2019 08:11:31|      110|           0.58|0.5537749999999892|\n",
      "|03/05/2019 08:16:31|      110|           0.55|0.5537749999999892|\n",
      "|03/05/2019 08:21:31|      110|           0.63|0.5537749999999892|\n",
      "|03/05/2019 08:26:31|      110|           0.63|0.5537749999999892|\n",
      "|03/05/2019 08:31:31|      110|           0.71|0.5537749999999892|\n",
      "|03/05/2019 08:36:31|      110|           0.67|0.5537749999999892|\n",
      "|03/05/2019 08:41:31|      110|           0.55|0.5537749999999892|\n",
      "|03/05/2019 08:46:31|      110|           0.37|0.5537749999999892|\n",
      "|03/05/2019 08:51:31|      110|            0.7|0.5537749999999892|\n",
      "|03/05/2019 08:56:31|      110|           0.67|0.5537749999999892|\n",
      "|03/05/2019 09:01:31|      110|           0.56|0.5537749999999892|\n",
      "|03/05/2019 09:06:31|      110|           0.37|0.5537749999999892|\n",
      "|03/05/2019 09:11:31|      110|            0.6|0.5537749999999892|\n",
      "|03/05/2019 09:16:31|      110|           0.45|0.5537749999999892|\n",
      "|03/05/2019 09:21:31|      110|           0.65|0.5537749999999892|\n",
      "|03/05/2019 09:26:31|      110|           0.45|0.5537749999999892|\n",
      "|03/05/2019 09:31:31|      110|           0.67|0.5537749999999892|\n",
      "|03/05/2019 09:36:31|      110|            0.5|0.5537749999999892|\n",
      "|03/05/2019 09:41:31|      110|           0.53|0.5537749999999892|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlwindow = spark.sql('''\n",
    "    select\n",
    "        event_datetime,\n",
    "        server_id,\n",
    "        cpu_utilization,\n",
    "        avg(cpu_utilization)\n",
    "        over (\n",
    "            partition by server_id\n",
    "        ) as avg_server_util\n",
    "    from utilization\n",
    "    ''')\n",
    "    \n",
    "sqlwindow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|   delta_server_util|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|03/05/2019 08:06:31|      110|           0.68|0.5537749999999892|  0.1262250000000108|\n",
      "|03/05/2019 08:11:31|      110|           0.58|0.5537749999999892|0.026225000000010712|\n",
      "|03/05/2019 08:16:31|      110|           0.55|0.5537749999999892|-0.00377499999998...|\n",
      "|03/05/2019 08:21:31|      110|           0.63|0.5537749999999892| 0.07622500000001076|\n",
      "|03/05/2019 08:26:31|      110|           0.63|0.5537749999999892| 0.07622500000001076|\n",
      "|03/05/2019 08:31:31|      110|           0.71|0.5537749999999892| 0.15622500000001072|\n",
      "|03/05/2019 08:36:31|      110|           0.67|0.5537749999999892| 0.11622500000001079|\n",
      "|03/05/2019 08:41:31|      110|           0.55|0.5537749999999892|-0.00377499999998...|\n",
      "|03/05/2019 08:46:31|      110|           0.37|0.5537749999999892|-0.18377499999998925|\n",
      "|03/05/2019 08:51:31|      110|            0.7|0.5537749999999892|  0.1462250000000107|\n",
      "|03/05/2019 08:56:31|      110|           0.67|0.5537749999999892| 0.11622500000001079|\n",
      "|03/05/2019 09:01:31|      110|           0.56|0.5537749999999892|0.006225000000010805|\n",
      "|03/05/2019 09:06:31|      110|           0.37|0.5537749999999892|-0.18377499999998925|\n",
      "|03/05/2019 09:11:31|      110|            0.6|0.5537749999999892| 0.04622500000001073|\n",
      "|03/05/2019 09:16:31|      110|           0.45|0.5537749999999892|-0.10377499999998924|\n",
      "|03/05/2019 09:21:31|      110|           0.65|0.5537749999999892| 0.09622500000001077|\n",
      "|03/05/2019 09:26:31|      110|           0.45|0.5537749999999892|-0.10377499999998924|\n",
      "|03/05/2019 09:31:31|      110|           0.67|0.5537749999999892| 0.11622500000001079|\n",
      "|03/05/2019 09:36:31|      110|            0.5|0.5537749999999892|-0.05377499999998925|\n",
      "|03/05/2019 09:41:31|      110|           0.53|0.5537749999999892|-0.02377499999998922|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlwindow2 = spark.sql('''\n",
    "    select\n",
    "        event_datetime,\n",
    "        server_id,\n",
    "        cpu_utilization,\n",
    "        avg(cpu_utilization)\n",
    "        over (\n",
    "            partition by server_id\n",
    "        ) as avg_server_util,\n",
    "        cpu_utilization - avg(cpu_utilization) \n",
    "        over (\n",
    "            partition by server_id\n",
    "        ) as delta_server_util\n",
    "    from utilization\n",
    "    ''')\n",
    "    \n",
    "sqlwindow2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|    avg_server_util|\n",
      "+-------------------+---------+---------------+-------------------+\n",
      "|03/05/2019 08:06:31|      110|           0.68|               0.63|\n",
      "|03/05/2019 08:11:31|      110|           0.58| 0.6033333333333334|\n",
      "|03/05/2019 08:16:31|      110|           0.55| 0.5866666666666666|\n",
      "|03/05/2019 08:21:31|      110|           0.63| 0.6033333333333334|\n",
      "|03/05/2019 08:26:31|      110|           0.63| 0.6566666666666666|\n",
      "|03/05/2019 08:31:31|      110|           0.71| 0.6699999999999999|\n",
      "|03/05/2019 08:36:31|      110|           0.67| 0.6433333333333333|\n",
      "|03/05/2019 08:41:31|      110|           0.55| 0.5300000000000001|\n",
      "|03/05/2019 08:46:31|      110|           0.37|               0.54|\n",
      "|03/05/2019 08:51:31|      110|            0.7|               0.58|\n",
      "|03/05/2019 08:56:31|      110|           0.67| 0.6433333333333334|\n",
      "|03/05/2019 09:01:31|      110|           0.56| 0.5333333333333333|\n",
      "|03/05/2019 09:06:31|      110|           0.37|               0.51|\n",
      "|03/05/2019 09:11:31|      110|            0.6|0.47333333333333333|\n",
      "|03/05/2019 09:16:31|      110|           0.45| 0.5666666666666668|\n",
      "|03/05/2019 09:21:31|      110|           0.65| 0.5166666666666667|\n",
      "|03/05/2019 09:26:31|      110|           0.45|               0.59|\n",
      "|03/05/2019 09:31:31|      110|           0.67|               0.54|\n",
      "|03/05/2019 09:36:31|      110|            0.5| 0.5666666666666667|\n",
      "|03/05/2019 09:41:31|      110|           0.53| 0.5133333333333333|\n",
      "+-------------------+---------+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlwindow3 = spark.sql('''\n",
    "    select\n",
    "        event_datetime,\n",
    "        server_id,\n",
    "        cpu_utilization,\n",
    "        avg(cpu_utilization)\n",
    "        over (\n",
    "            partition by server_id\n",
    "            order by 1\n",
    "            rows between 1 preceding and 1 following\n",
    "        ) as avg_server_util\n",
    "    from utilization\n",
    "    ''')\n",
    "    \n",
    "sqlwindow3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843ed4014e0c5c9016b0be3f012b8ea5a0b4055cbc7abd39c785865cd85ff6da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
