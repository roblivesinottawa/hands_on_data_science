{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiate a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/25 18:36:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/25 18:36:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/25 18:36:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/03/25 18:36:07 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://robsons-imac.lan:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f94a6a073a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('json').load('/Users/rob_the_programmer/Documents/programming/2022/hands_on_data_science/spark-sql-dataframes-workspace/files/utlization.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=['cpu_utilization', 'free_memory', 'session_count'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorcluster = va.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+----------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|        features|\n",
      "+---------------+-------------------+-----------+---------+-------------+----------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|[0.57,0.51,47.0]|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|[0.47,0.62,43.0]|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|[0.56,0.57,62.0]|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|[0.57,0.56,50.0]|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|[0.35,0.46,43.0]|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|[0.41,0.58,48.0]|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|[0.57,0.35,58.0]|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58| [0.41,0.4,58.0]|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|[0.53,0.35,62.0]|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45| [0.51,0.6,45.0]|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|[0.32,0.37,47.0]|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|[0.62,0.59,60.0]|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|[0.66,0.72,57.0]|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|[0.54,0.54,44.0]|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47| [0.29,0.4,47.0]|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|[0.43,0.68,66.0]|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|[0.49,0.66,65.0]|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|[0.64,0.55,66.0]|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42| [0.42,0.6,42.0]|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|[0.55,0.59,63.0]|\n",
      "+---------------+-------------------+-----------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorcluster.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(3)\n",
    "kmeans = kmeans.setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "kmodel = kmeans.fit(vectorcluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.62881549,  0.37094643, 70.43030159]),\n",
       " array([ 0.52047775,  0.47836303, 51.79927162]),\n",
       " array([ 0.71931575,  0.28104316, 88.23965784])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/26 07:07:12 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 7186814 ms exceeds timeout 120000 ms\n",
      "22/03/26 07:07:19 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "kmodel.clusterCenters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+--------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|features|\n",
      "+---------------+-------------------+-----------+---------+-------------+--------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|  [0.57]|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|  [0.47]|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|  [0.56]|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|  [0.57]|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|  [0.35]|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|  [0.41]|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|  [0.57]|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|  [0.41]|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|  [0.53]|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|  [0.51]|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|  [0.32]|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|  [0.62]|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|  [0.66]|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|  [0.54]|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|  [0.29]|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|  [0.43]|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|  [0.49]|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|  [0.64]|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|  [0.42]|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|  [0.55]|\n",
      "+---------------+-------------------+-----------+---------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols=['cpu_utilization'], outputCol='features')\n",
    "dfvectorutil = va.transform(df)\n",
    "dfvectorutil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='session_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/26 10:09:46 WARN Instrumentation: [39fa4088] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/03/26 10:09:48 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/03/26 10:09:48 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/03/26 10:09:58 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lrmodel = lr.fit(dfvectorutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([47.024])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.416951035523695"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.intercept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.83799022593174"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843ed4014e0c5c9016b0be3f012b8ea5a0b4055cbc7abd39c785865cd85ff6da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
